from dotenv import load_dotenv
load_dotenv()

import os
import json
from deepeval.test_case import LLMTestCase
from deepeval.metrics import AnswerRelevancyMetric, FaithfulnessMetric, HallucinationMetric

# âœ… è‡ªé€‚åº”æˆªæ–­ï¼šç¡®ä¿å­—ç¬¦é•¿åº¦ä¸è¶…è¿‡é™åˆ¶
def adaptive_truncate(text: str, max_tokens: int = 2000, max_char_len: int = 8000) -> str:
    while max_tokens > 200:
        truncated = text[:max_tokens * 4]
        if len(truncated) <= max_char_len:
            return truncated
        max_tokens = int(max_tokens * 0.8)
    return text[:max_char_len]

# âœ… é¡¹ç›®è·¯å¾„è®¾ç½®
ROOT_DIR = os.path.abspath(os.path.join(os.path.dirname(__file__), "..", ".."))
output_root = os.path.join(ROOT_DIR, "output")
retrieved_root = os.path.join(ROOT_DIR, "extracted_info")
save_root = os.path.join(ROOT_DIR, "eval_results")
os.makedirs(save_root, exist_ok=True)

# âœ… åˆå§‹åŒ–è¯„ä¼°æŒ‡æ ‡
metrics = {
    "answer_relevancy": AnswerRelevancyMetric(),
    "faithfulness": FaithfulnessMetric(),
    "hallucination": HallucinationMetric()
}

# âœ… å·²è¯„ä¼°é¢‘é“åˆ—è¡¨
existing_results = {
    fname.replace("_all_metrics.json", "") for fname in os.listdir(save_root)
    if fname.endswith("_all_metrics.json")
}

# âœ… æ ¼å¼åŒ– gen_data ä¸­çš„å€¼
def format_value(v):
    if isinstance(v, str):
        return v
    elif isinstance(v, list) and all(isinstance(x, str) for x in v):
        return "; ".join(v)
    else:
        return None  # å¿½ç•¥å…¶ä»–ç±»åž‹

# âœ… éåŽ†æ‰€æœ‰é¢‘é“
for video_id in os.listdir(output_root):
    if video_id in existing_results:
        print(f"â­ï¸ å·²å­˜åœ¨è¯„ä¼°ç»“æžœï¼Œè·³è¿‡: {video_id}")
        continue

    video_path = os.path.join(output_root, video_id)
    if not os.path.isdir(video_path):
        continue

    print(f"\nðŸ“º æ­£åœ¨è¯„ä¼°é¢‘é“: {video_id}")
    retrieved_file = os.path.join(retrieved_root, f"{video_id}_extract.json")
    if not os.path.exists(retrieved_file):
        print(f"âŒ ç¼ºå°‘ retrieved_context æ–‡ä»¶: {retrieved_file}")
        continue

    # === åŠ è½½ä¸Šä¸‹æ–‡å¹¶æˆªæ–­ ===
    with open(retrieved_file, "r") as f:
        retrieved_data = json.load(f)
    all_desc = [v.get("description", "") for v in retrieved_data.values() if isinstance(v, dict)]
    retrieved_context = adaptive_truncate("\n".join(all_desc).strip(), max_tokens=1500, max_char_len=6000)
    print(f"ðŸ§  retrieved_context é•¿åº¦: {len(retrieved_context)} å­—ç¬¦")

    # === éåŽ†æ¨¡åž‹è¾“å‡º ===
    channel_results = {}
    for fname in os.listdir(video_path):
        if not fname.endswith(".json") or "_metrics.json" in fname:
            continue

        model_key = fname.replace(f"{video_id}_", "").replace("_free_analysis.json", "")
        generated_file = os.path.join(video_path, fname)

        with open(generated_file, "r") as f:
            gen_data = json.load(f)

        # âœ… å¤„ç† str / List[str]
        generated_output = "\n".join([
            f"{k}: {formatted}" for k, v in gen_data.items()
            if (formatted := format_value(v)) is not None
        ]).strip()

        # âœ… æˆªæ–­ç”Ÿæˆå†…å®¹å¹¶è¾“å‡ºé•¿åº¦
        generated_output = adaptive_truncate(generated_output, max_tokens=2000, max_char_len=8000)
        print(f"ðŸ“ generated_output é•¿åº¦: {len(generated_output)} å­—ç¬¦")

        if not generated_output:
            print(f"âš ï¸ ç”Ÿæˆå†…å®¹ä¸ºç©ºï¼Œè·³è¿‡: {fname}")
            continue

        test_case = LLMTestCase(
            input=retrieved_context,
            actual_output=generated_output,
            retrieval_context=[retrieved_context],
            context=[retrieved_context]
        )

        result = {}
        for name, metric in metrics.items():
            try:
                score = metric.measure(test_case)
                print(f"   ðŸ“Š {model_key} | {name:<20} â†’ Score: {score:.4f}")
                result[name] = float(score)
            except Exception as e:
                print(f"   âŒ {model_key} | {name:<20} failed: {e}")
                result[name] = None

        channel_results[model_key] = result

    # âœ… ä»…åœ¨å­˜åœ¨æœ‰æ•ˆæ¨¡åž‹æ—¶ä¿å­˜ç»“æžœ
    if channel_results:
        save_path = os.path.join(save_root, f"{video_id}_all_metrics.json")
        with open(save_path, "w") as f:
            json.dump(channel_results, f, indent=2)
        print(f"âœ… å·²ä¿å­˜è¯„ä¼°ç»“æžœ: {save_path}")
    else:
        print(f"âš ï¸ æ‰€æœ‰æ¨¡åž‹éƒ½è¢«è·³è¿‡ï¼Œæœªä¿å­˜è¯„ä¼°æ–‡ä»¶: {video_id}")
